{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import dtLoader\n",
    "import numpy as np\n",
    "import pywt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"/Users/pradithaalwis/Projects/University of Peradeniya/Fetal Mov Data/Ward/\"\n",
    "drop_zero_path = \"/Users/pradithaalwis/Projects/University of Peradeniya/Fetal Mov Data//Randomly_Dropped_Windows/\"\n",
    "sensors = ['ax1', 'ay1', 'az1', 'ax2', 'ay2', 'az2', 'ax3', 'ay3', 'az3', 'ax4', 'ay4', 'az4']\n",
    "sample_freq = 32\n",
    "\n",
    "# Stride in seconds\n",
    "stride = 1\n",
    "\n",
    "# Window length in seconds\n",
    "window_length = 8\n",
    "\n",
    "# Safety margin in seconds\n",
    "front_margin = 2\n",
    "rear_margin = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Splits the signals into windows\n",
    "Args:\n",
    "    SOURCE          : path to the sensor data\n",
    "    SAMPLE_FREQ     : sample frequency of sensors\n",
    "    STRIDE          : stride used for windowing (in seconds)\n",
    "    WINDOW_LENGTH   : length of the required window in seconds\n",
    "    FRONT_MARGIN    : Required offset before a fetal kick (in seconds)\n",
    "    REAR_MARGIN     : Required offset after a fetal kick (in seconds)\n",
    "\"\"\"\n",
    "dataloader = dtLoader(SOURCE=source,\n",
    "                        SAMPLE_FREQ=sample_freq,\n",
    "                        STRIDE=stride,\n",
    "                        WINDOW_LENGTH=window_length,\n",
    "                        FRONT_MARGIN=front_margin,\n",
    "                        REAR_MARGIN=rear_margin,\n",
    "                        SENSORS=sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "These are the list of files in the source directory.\n",
      "['W17_R1.csv', 'W09_R1.csv', 'W05_R1.csv', 'W21_R1.csv', 'W05_R2.csv', 'W21_R2.csv', 'W15_R2.csv', 'W19_R1.csv', 'W07_R1.csv', 'W15_R1.csv', 'W23_R1.csv', 'W11_R3.csv', 'W27_R2.csv', 'W11_R2.csv', 'W27_R1.csv', 'W11_R1.csv', 'W03_R1.csv', 'W25_R1.csv', 'W11_R5.csv', 'W29_R1.csv', 'W01_R1.csv', 'W11_R4.csv', 'W13_R1.csv', 'W25_R2.csv', 'W29_R2.csv', 'W29_R3.csv', 'W25_R3.csv', 'W04_R2.csv', 'W20_R1.csv', 'W08_R1.csv', 'W16_R1.csv', 'W04_R1.csv', 'W22_R1.csv', 'W30_R1.csv', 'W06_R1.csv', 'W18_R1.csv', 'W14_R1.csv', 'W22_R2.csv', 'W10_R1.csv', 'W02_R1.csv', 'W26_R1.csv', 'W24_R3.csv', 'W24_R2.csv', 'W12_R1.csv', 'W24_R1.csv', 'W28_R1.csv']\n",
      "--------------------------------------------------------------------------------\n",
      "Length of dataframe :  1286  seconds\n",
      "W17_R1.csv has been processed\n",
      "Length of dataframe :  1263  seconds\n",
      "W09_R1.csv has been processed\n",
      "Length of dataframe :  1241  seconds\n",
      "W05_R1.csv has been processed\n",
      "Length of dataframe :  717  seconds\n",
      "W21_R1.csv has been processed\n",
      "Length of dataframe :  18  seconds\n",
      "W05_R2.csv has been processed\n",
      "Length of dataframe :  244  seconds\n",
      "W21_R2.csv has been processed\n",
      "Length of dataframe :  477  seconds\n",
      "W15_R2.csv has been processed\n",
      "Length of dataframe :  830  seconds\n",
      "W19_R1.csv has been processed\n",
      "Length of dataframe :  905  seconds\n",
      "W07_R1.csv has been processed\n",
      "Length of dataframe :  493  seconds\n",
      "W15_R1.csv has been processed\n",
      "Length of dataframe :  1017  seconds\n",
      "W23_R1.csv has been processed\n",
      "Length of dataframe :  271  seconds\n",
      "W11_R3.csv has been processed\n",
      "Length of dataframe :  8  seconds\n",
      "W27_R2.csv has been processed\n",
      "Length of dataframe :  42  seconds\n",
      "W11_R2.csv has been processed\n",
      "Length of dataframe :  1121  seconds\n",
      "W27_R1.csv has been processed\n",
      "Length of dataframe :  592  seconds\n",
      "W11_R1.csv has been processed\n",
      "Length of dataframe :  1212  seconds\n",
      "W03_R1.csv has been processed\n",
      "Length of dataframe :  685  seconds\n",
      "W25_R1.csv has been processed\n",
      "Length of dataframe :  213  seconds\n",
      "W11_R5.csv has been processed\n",
      "Length of dataframe :  1187  seconds\n",
      "W29_R1.csv has been processed\n",
      "Length of dataframe :  1362  seconds\n",
      "W01_R1.csv has been processed\n",
      "Length of dataframe :  379  seconds\n",
      "W11_R4.csv has been processed\n",
      "Length of dataframe :  1006  seconds\n",
      "W13_R1.csv has been processed\n",
      "Length of dataframe :  310  seconds\n",
      "W25_R2.csv has been processed\n",
      "Length of dataframe :  8  seconds\n",
      "W29_R2.csv has been processed\n",
      "Length of dataframe :  31  seconds\n",
      "W29_R3.csv has been processed\n",
      "Length of dataframe :  8  seconds\n",
      "W25_R3.csv has been processed\n",
      "Length of dataframe :  782  seconds\n",
      "W04_R2.csv has been processed\n",
      "Length of dataframe :  913  seconds\n",
      "W20_R1.csv has been processed\n",
      "Length of dataframe :  916  seconds\n",
      "W08_R1.csv has been processed\n",
      "Length of dataframe :  1201  seconds\n",
      "W16_R1.csv has been processed\n",
      "Length of dataframe :  258  seconds\n",
      "W04_R1.csv has been processed\n",
      "Length of dataframe :  389  seconds\n",
      "W22_R1.csv has been processed\n",
      "Length of dataframe :  544  seconds\n",
      "W30_R1.csv has been processed\n",
      "Length of dataframe :  1238  seconds\n",
      "W06_R1.csv has been processed\n",
      "Length of dataframe :  662  seconds\n",
      "W18_R1.csv has been processed\n",
      "Length of dataframe :  673  seconds\n",
      "W14_R1.csv has been processed\n",
      "Length of dataframe :  606  seconds\n",
      "W22_R2.csv has been processed\n",
      "Length of dataframe :  1292  seconds\n",
      "W10_R1.csv has been processed\n",
      "Length of dataframe :  1265  seconds\n",
      "W02_R1.csv has been processed\n",
      "Length of dataframe :  1213  seconds\n",
      "W26_R1.csv has been processed\n",
      "Length of dataframe :  8  seconds\n",
      "W24_R3.csv has been processed\n",
      "Length of dataframe :  929  seconds\n",
      "W24_R2.csv has been processed\n",
      "Length of dataframe :  1394  seconds\n",
      "W12_R1.csv has been processed\n",
      "Length of dataframe :  189  seconds\n",
      "W24_R1.csv has been processed\n",
      "Length of dataframe :  392  seconds\n",
      "W28_R1.csv has been processed\n",
      "30336 windows have been generated\n",
      "Maximum number of kicks in a window : 6\n",
      "--------------------------------------------------------------------------------\n",
      "0  kick windows :  28537\n",
      "1  kick windows :  1565\n",
      "2  kick windows :  207\n",
      "3  kick windows :  21\n",
      "4  kick windows :  4\n",
      "5  kick windows :  0\n",
      "6  kick windows :  2\n",
      "--------------------------------------------------------------------------------\n",
      "Total number of kicks : 356\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Args:\n",
    "Returns:\n",
    "    self.window_list            : Set of generated windows\n",
    "    self.kick_count_list        : Number of kicks in each window\n",
    "    counts                      : Dictionary containing number of windows                             with the given number of kicks\n",
    "\"\"\"\n",
    "counts = dataloader.split_windows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_list, num_kick_list = dataloader.drop_zero_kicks(counts[0] - counts[1], drop_zero_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3529, 12, 256)\n"
     ]
    }
   ],
   "source": [
    "print(window_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_scalo(signal):\n",
    "    values = np.geomspace(1, 32, num=64)\n",
    "    widths = []\n",
    "    sample_freq = 32\n",
    "    frequencies = pywt.scale2frequency('cmor2.5-0.5', values) * sample_freq\n",
    "\n",
    "    for i in range(len(values)):\n",
    "        if frequencies[i] > 2:\n",
    "            widths.append(values[i])\n",
    "    C = 0.5\n",
    "    B = 2.5\n",
    "    cwtmatr, freqs = pywt.cwt(window_list[0][2], widths, 'cmor' + str(B) + '+' + str(C), sampling_period= 1 / sample_freq, method='fft')\n",
    "    cwtmatr = np.abs(cwtmatr[:-1, :-1]) ** 2\n",
    "    return cwtmatr, freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should randomize this selection\n",
    "scalograms = []\n",
    "for i in range(len(num_kick_list)):\n",
    "    temp = []\n",
    "    for sensor in window_list[i]:\n",
    "        cwtmatr, freq = gen_scalo(sensor)\n",
    "        normed_matrix = normalize(cwtmatr, axis=1, norm='l1')\n",
    "        temp.append(cwtmatr)\n",
    "    temp = np.array(temp, dtype=np.float32)\n",
    "    scalograms.append(temp)\n",
    "scalograms = np.array(scalograms, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(min(num_kick_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalograms_0 = []\n",
    "scalograms_1 = []\n",
    "scalograms_2 = []\n",
    "scalograms_3 = []\n",
    "for i in range(len(scalograms)):\n",
    "    match num_kick_list[i]:\n",
    "        case 0:\n",
    "            scalograms_0.append(scalograms[i])\n",
    "        case 1:\n",
    "            scalograms_1.append(scalograms[i])\n",
    "        case 2:\n",
    "            scalograms_2.append(scalograms[i])\n",
    "        case 3:\n",
    "            scalograms_3.append(scalograms[i])\n",
    "        case _:\n",
    "            print(\"Unknown Class!!!\")\n",
    "del scalograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0, X_test_0, y_train_0, y_test_0 = train_test_split(scalograms_0, [0 for i in range(len(scalograms_0))], test_size=0.2)\n",
    "del scalograms_0\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(scalograms_1, [1 for i in range(len(scalograms_1))], test_size=0.2)\n",
    "del scalograms_1\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(scalograms_2, [2 for i in range(len(scalograms_2))], test_size=0.2)\n",
    "del scalograms_2\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(scalograms_3, [3 for i in range(len(scalograms_3))], test_size=0.2)\n",
    "del scalograms_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1384 1252 165 21\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_0), len(X_train_1), len(X_train_2), len(X_train_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_0\n",
    "del X_train_0\n",
    "X_train.extend(X_train_1)\n",
    "del X_train_1\n",
    "X_train.extend(X_train_2)\n",
    "del X_train_2\n",
    "X_train.extend(X_train_3)\n",
    "del X_train_3\n",
    "\n",
    "y_train = y_train_0\n",
    "del y_train_0\n",
    "y_train.extend(y_train_1)\n",
    "del y_train_1\n",
    "y_train.extend(y_train_2)\n",
    "del y_train_2\n",
    "y_train.extend(y_train_3)\n",
    "del y_train_3\n",
    "\n",
    "X_train = np.array(X_train, dtype=np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_0\n",
    "del X_test_0\n",
    "X_test.extend(X_test_1)\n",
    "del X_test_1\n",
    "X_test.extend(X_test_2)\n",
    "del X_test_2\n",
    "X_test.extend(X_test_3)\n",
    "del X_test_3\n",
    "\n",
    "y_test = y_test_0\n",
    "del y_test_0\n",
    "y_test.extend(y_test_1)\n",
    "del y_test_1\n",
    "y_test.extend(y_test_2)\n",
    "del y_test_2\n",
    "y_test.extend(y_test_3)\n",
    "del y_test_3\n",
    "\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(707, 12, 37, 255) (707,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to torch tensors\n",
    "class Data(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.from_numpy(X.astype(np.float32))\n",
    "        self.y = torch.from_numpy(y.astype(np.longlong))\n",
    "        self.len = self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "class CustomToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        # Swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        print(sample[1].shape, sample[1])\n",
    "        return (torch.from_numpy(sample[0]).to(torch.float32).to(\"mps\"), torch.from_numpy(sample[1]).to(torch.long))\n",
    "class CustomNormalize(object):\n",
    "    \"\"\"Normalize an image with mean and standard deviation.\"\"\"\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = torch.tensor(mean).to(torch.float32).to(\"mps\")\n",
    "        self.std = torch.tensor(std).to(torch.float32).to(\"mps\")\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "transform = transforms.Compose(\n",
    "    [CustomToTensor(),\n",
    "    CustomNormalize(mean=[0.5] * 12, std=[0.5] * 12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Data(X_train, y_train)\n",
    "test_data = Data(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)#, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)#, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        num_channels = 12\n",
    "        self.conv1 = nn.Conv2d(num_channels, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 60, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# print images\n",
    "# imshow(torchvision.utils.make_grid(images))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 707\n"
     ]
    }
   ],
   "source": [
    "print(correct, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.271570014144274\n"
     ]
    }
   ],
   "source": [
    "print((correct / total) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
