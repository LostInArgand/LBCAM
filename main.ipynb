{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import dtLoader\n",
    "import numpy as np\n",
    "import pywt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"/Users/pradithaalwis/Projects/University of Peradeniya/Fetal Mov Data/Ward/\"\n",
    "drop_zero_path = \"/Users/pradithaalwis/Projects/University of Peradeniya/Fetal Mov Data//Randomly_Dropped_Windows/\"\n",
    "sensors = ['ax1', 'ay1', 'az1', 'ax2', 'ay2', 'az2', 'ax3', 'ay3', 'az3', 'ax4', 'ay4', 'az4']\n",
    "sample_freq = 32\n",
    "\n",
    "# Stride in seconds\n",
    "stride = 1\n",
    "\n",
    "# Window length in seconds\n",
    "window_length = 8\n",
    "\n",
    "# Safety margin in seconds\n",
    "front_margin = 2\n",
    "rear_margin = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Splits the signals into windows\n",
    "Args:\n",
    "    SOURCE          : path to the sensor data\n",
    "    SAMPLE_FREQ     : sample frequency of sensors\n",
    "    STRIDE          : stride used for windowing (in seconds)\n",
    "    WINDOW_LENGTH   : length of the required window in seconds\n",
    "    FRONT_MARGIN    : Required offset before a fetal kick (in seconds)\n",
    "    REAR_MARGIN     : Required offset after a fetal kick (in seconds)\n",
    "\"\"\"\n",
    "dataloader = dtLoader(SOURCE=source,\n",
    "                        SAMPLE_FREQ=sample_freq,\n",
    "                        STRIDE=stride,\n",
    "                        WINDOW_LENGTH=window_length,\n",
    "                        FRONT_MARGIN=front_margin,\n",
    "                        REAR_MARGIN=rear_margin,\n",
    "                        SENSORS=sensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "These are the list of files in the source directory.\n",
      "['W17_R1.csv', 'W09_R1.csv', 'W05_R1.csv', 'W21_R1.csv', 'W05_R2.csv', 'W21_R2.csv', 'W15_R2.csv', 'W19_R1.csv', 'W07_R1.csv', 'W15_R1.csv', 'W23_R1.csv', 'W11_R3.csv', 'W27_R2.csv', 'W11_R2.csv', 'W27_R1.csv', 'W11_R1.csv', 'W03_R1.csv', 'W25_R1.csv', 'W11_R5.csv', 'W29_R1.csv', 'W01_R1.csv', 'W11_R4.csv', 'W13_R1.csv', 'W25_R2.csv', 'W29_R2.csv', 'W29_R3.csv', 'W25_R3.csv', 'W04_R2.csv', 'W20_R1.csv', 'W08_R1.csv', 'W16_R1.csv', 'W04_R1.csv', 'W22_R1.csv', 'W30_R1.csv', 'W06_R1.csv', 'W18_R1.csv', 'W14_R1.csv', 'W22_R2.csv', 'W10_R1.csv', 'W02_R1.csv', 'W26_R1.csv', 'W24_R3.csv', 'W24_R2.csv', 'W12_R1.csv', 'W24_R1.csv', 'W28_R1.csv']\n",
      "--------------------------------------------------------------------------------\n",
      "Length of dataframe :  1286  seconds\n",
      "W17_R1.csv has been processed\n",
      "Length of dataframe :  1263  seconds\n",
      "W09_R1.csv has been processed\n",
      "Length of dataframe :  1241  seconds\n",
      "W05_R1.csv has been processed\n",
      "Length of dataframe :  717  seconds\n",
      "W21_R1.csv has been processed\n",
      "Length of dataframe :  18  seconds\n",
      "W05_R2.csv has been processed\n",
      "Length of dataframe :  244  seconds\n",
      "W21_R2.csv has been processed\n",
      "Length of dataframe :  477  seconds\n",
      "W15_R2.csv has been processed\n",
      "Length of dataframe :  830  seconds\n",
      "W19_R1.csv has been processed\n",
      "Length of dataframe :  905  seconds\n",
      "W07_R1.csv has been processed\n",
      "Length of dataframe :  493  seconds\n",
      "W15_R1.csv has been processed\n",
      "Length of dataframe :  1017  seconds\n",
      "W23_R1.csv has been processed\n",
      "Length of dataframe :  271  seconds\n",
      "W11_R3.csv has been processed\n",
      "Length of dataframe :  8  seconds\n",
      "W27_R2.csv has been processed\n",
      "Length of dataframe :  42  seconds\n",
      "W11_R2.csv has been processed\n",
      "Length of dataframe :  1121  seconds\n",
      "W27_R1.csv has been processed\n",
      "Length of dataframe :  592  seconds\n",
      "W11_R1.csv has been processed\n",
      "Length of dataframe :  1212  seconds\n",
      "W03_R1.csv has been processed\n",
      "Length of dataframe :  685  seconds\n",
      "W25_R1.csv has been processed\n",
      "Length of dataframe :  213  seconds\n",
      "W11_R5.csv has been processed\n",
      "Length of dataframe :  1187  seconds\n",
      "W29_R1.csv has been processed\n",
      "Length of dataframe :  1362  seconds\n",
      "W01_R1.csv has been processed\n",
      "Length of dataframe :  379  seconds\n",
      "W11_R4.csv has been processed\n",
      "Length of dataframe :  1006  seconds\n",
      "W13_R1.csv has been processed\n",
      "Length of dataframe :  310  seconds\n",
      "W25_R2.csv has been processed\n",
      "Length of dataframe :  8  seconds\n",
      "W29_R2.csv has been processed\n",
      "Length of dataframe :  31  seconds\n",
      "W29_R3.csv has been processed\n",
      "Length of dataframe :  8  seconds\n",
      "W25_R3.csv has been processed\n",
      "Length of dataframe :  782  seconds\n",
      "W04_R2.csv has been processed\n",
      "Length of dataframe :  913  seconds\n",
      "W20_R1.csv has been processed\n",
      "Length of dataframe :  916  seconds\n",
      "W08_R1.csv has been processed\n",
      "Length of dataframe :  1201  seconds\n",
      "W16_R1.csv has been processed\n",
      "Length of dataframe :  258  seconds\n",
      "W04_R1.csv has been processed\n",
      "Length of dataframe :  389  seconds\n",
      "W22_R1.csv has been processed\n",
      "Length of dataframe :  544  seconds\n",
      "W30_R1.csv has been processed\n",
      "Length of dataframe :  1238  seconds\n",
      "W06_R1.csv has been processed\n",
      "Length of dataframe :  662  seconds\n",
      "W18_R1.csv has been processed\n",
      "Length of dataframe :  673  seconds\n",
      "W14_R1.csv has been processed\n",
      "Length of dataframe :  606  seconds\n",
      "W22_R2.csv has been processed\n",
      "Length of dataframe :  1292  seconds\n",
      "W10_R1.csv has been processed\n",
      "Length of dataframe :  1265  seconds\n",
      "W02_R1.csv has been processed\n",
      "Length of dataframe :  1213  seconds\n",
      "W26_R1.csv has been processed\n",
      "Length of dataframe :  8  seconds\n",
      "W24_R3.csv has been processed\n",
      "Length of dataframe :  929  seconds\n",
      "W24_R2.csv has been processed\n",
      "Length of dataframe :  1394  seconds\n",
      "W12_R1.csv has been processed\n",
      "Length of dataframe :  189  seconds\n",
      "W24_R1.csv has been processed\n",
      "Length of dataframe :  392  seconds\n",
      "W28_R1.csv has been processed\n",
      "30336 windows have been generated\n",
      "Maximum number of kicks in a window : 6\n",
      "--------------------------------------------------------------------------------\n",
      "0  kick windows :  28537\n",
      "1  kick windows :  1565\n",
      "2  kick windows :  207\n",
      "3  kick windows :  21\n",
      "4  kick windows :  4\n",
      "5  kick windows :  0\n",
      "6  kick windows :  2\n",
      "--------------------------------------------------------------------------------\n",
      "Total number of kicks : 356\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Args:\n",
    "Returns:\n",
    "    self.window_list            : Set of generated windows\n",
    "    self.kick_count_list        : Number of kicks in each window\n",
    "    counts                      : Dictionary containing number of windows                             with the given number of kicks\n",
    "\"\"\"\n",
    "counts = dataloader.split_windows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_list, num_kick_list = dataloader.drop_zero_kicks(counts[0] - counts[1], drop_zero_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3516, 12, 256)\n"
     ]
    }
   ],
   "source": [
    "print(window_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_scalo(signal):\n",
    "    values = np.geomspace(1, 32, num=64)\n",
    "    widths = []\n",
    "    sample_freq = 32\n",
    "    frequencies = pywt.scale2frequency('cmor2.5-0.5', values) * sample_freq\n",
    "\n",
    "    for i in range(len(values)):\n",
    "        if frequencies[i] > 2:\n",
    "            widths.append(values[i])\n",
    "    C = 0.5\n",
    "    B = 2.5\n",
    "    cwtmatr, freqs = pywt.cwt(window_list[0][2], widths, 'cmor' + str(B) + '+' + str(C), sampling_period= 1 / sample_freq, method='fft')\n",
    "    cwtmatr = np.abs(cwtmatr[:-1, :-1]) ** 2\n",
    "    return cwtmatr, freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should randomize this selection\n",
    "scalograms = []\n",
    "for i in range(len(num_kick_list)):\n",
    "    temp = []\n",
    "    for sensor in window_list[i]:\n",
    "        cwtmatr, freq = gen_scalo(sensor)\n",
    "        normed_matrix = normalize(cwtmatr, axis=1, norm='l1')\n",
    "        temp.append(cwtmatr)\n",
    "    temp = np.array(temp, dtype=np.float32)\n",
    "    scalograms.append(temp)\n",
    "scalograms = np.array(scalograms, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(min(num_kick_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3516, 12, 37, 255)\n"
     ]
    }
   ],
   "source": [
    "print(scalograms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 255)\n"
     ]
    }
   ],
   "source": [
    "print(temp[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "class CustomToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        # Swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        print(sample[1].shape, sample[1])\n",
    "        return (torch.from_numpy(sample[0]).to(torch.float32).to(\"cpu\"), torch.from_numpy(sample[1]).to(torch.long))\n",
    "class CustomNormalize(object):\n",
    "    \"\"\"Normalize an image with mean and standard deviation.\"\"\"\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = torch.tensor(mean).to(torch.float32).to(\"cpu\")\n",
    "        self.std = torch.tensor(std).to(torch.float32).to(\"cpu\")\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "transform = transforms.Compose(\n",
    "    [CustomToTensor(),\n",
    "    CustomNormalize(mean=[0.5] * 12, std=[0.5] * 12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3516, 12, 37, 255)\n",
      "(3516, 1)\n"
     ]
    }
   ],
   "source": [
    "print(scalograms.shape)\n",
    "num_kick_list = num_kick_list.reshape(len(num_kick_list), 1)\n",
    "print(num_kick_list.shape)\n",
    "\n",
    "# trainset = [transform((scalogram, gt)) for (scalogram, gt) in zip(scalograms, num_kick_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
